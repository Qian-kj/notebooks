<!DOCTYPE html>
<html>
    <head>
        







<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />



<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
    href="https://fonts.googleapis.com/css2?family=PT+Serif:ital,wght@0,400;0,700;1,400;1,700&display=swap"
    rel="stylesheet"
/>
<link
    href="https://cdn.jsdelivr.net/npm/@fontsource/cascadia-code@4.2.1/index.min.css"
    rel="stylesheet"
/>


<link rel="stylesheet" href="/notebooks/styles/main.css">


    
<link rel="stylesheet" href="/notebooks/styles/post.css">



<title>Chapter 10: Ranking - Brybry Royal Kindergarden</title>

    <meta name="generator" content="Hexo 6.3.0"></head>
    <body>
        <header>
    <nav>
        <ul>
            <li><a href="/notebooks/">Home</a></li>
            
                

    <li><a href="/notebooks/posts"><span>Posts</span></a></li>
    <li><a href="/notebooks/tags"><span>Tags</span></a></li>
    <li><a href="/notebooks/categories"><span>Categories</span></a></li>
    <li><a href="/notebooks/archives"><span>Archives</span></a></li>


            
        </ul>
    </nav>
</header>

        <main>
    <header>
        <h1>
            
                Chapter 10: Ranking
            
        </h1>
        <div>
            <time>2024-07-01</time>
            <div class="post-categories">
                
            </div>
            <div class="post-tags">
                
            </div>
        </div>
    </header>
    <h1 id="Chapter-10-Ranking"><a href="#Chapter-10-Ranking" class="headerlink" title="Chapter 10: Ranking"></a>Chapter 10: Ranking</h1><h1 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents"></a>Table of Contents</h1><ul>
<li><a href="#chapter-10-ranking">Chapter 10: Ranking</a></li>
<li><a href="#table-of-contents">Table of Contents</a></li>
<li><a href="#1-introduction">1. Introduction</a><ul>
<li><a href="#11-motivation-for-ranking">1.1 Motivation for Ranking</a><ul>
<li><a href="#1-resource-limitation-in-classification">(1) Resource Limitation in Classification:</a></li>
<li><a href="#2-examples">(2) Examples:</a></li>
</ul>
</li>
<li><a href="#12-two-general-settings-for-ranking">1.2 Two General Settings for Ranking</a></li>
<li><a href="#13-algorithms-discussed">1.3 Algorithms Discussed:</a><ul>
<li><a href="#1-svm-based-ranking-algorithm">(1) SVM-Based Ranking Algorithm:</a></li>
<li><a href="#2-rankboost">(2) RankBoost:</a></li>
<li><a href="#3-bipartite-ranking">(3) Bipartite Ranking:</a></li>
</ul>
</li>
<li><a href="#14-evaluation-metrics">1.4 Evaluation Metrics</a></li>
</ul>
</li>
<li><a href="#2-the-problem-of-ranking">2. The Problem of Ranking</a><ul>
<li><a href="#21-ranking-problem">2.1 Ranking Problem</a></li>
<li><a href="#22-scoring-function">2.2 Scoring Function</a></li>
<li><a href="#23-preference-function-f">2.3 Preference Function $f$</a><ul>
<li><a href="#1-definition">(1) Definition</a></li>
<li><a href="#2-non-transitivity">(2) Non-Transitivity</a></li>
</ul>
</li>
<li><a href="#24-labeled-sample">2.4 Labeled Sample</a></li>
<li><a href="#25-target">2.5 Target</a><ul>
<li><a href="#1-goal">(1) Goal</a></li>
<li><a href="#2-generalization-error-rh">(2) Generalization Error $R(h)$</a></li>
<li><a href="#3-empirical-error-hatr_sh">(3) Empirical Error $\hat{R}_S(h)$</a></li>
<li><a href="#4-key-points"><strong>(4) Key points:</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-generalization-bound">3. Generalization Bound</a><ul>
<li><a href="#31-margin-based-generalization-bounds">3.1 Margin-Based Generalization Bounds</a><ul>
<li><a href="#1-simplification">(1) Simplification:</a></li>
<li><a href="#2-empirical-margin-loss">(2) Empirical Margin Loss</a></li>
<li><a href="#3-margin-loss-and-pairwise-misranking">(3) Margin Loss and Pairwise Misranking</a></li>
</ul>
</li>
<li><a href="#32-theorem-101">3.2 Theorem 10.1</a><ul>
<li><a href="#1-distribution-d">(1) Distribution $D$</a></li>
<li><a href="#2-margin-bound-for-ranking">(2) Margin Bound for Ranking</a></li>
<li><a href="#3-proof">(3) Proof:</a></li>
<li><a href="#4-extension">(4) Extension:</a></li>
</ul>
</li>
<li><a href="#33-corollary-102">3.3 Corollary 10.2</a><ul>
<li><a href="#1-margin-bounds-with-kernel-based-hypotheses">(1) Margin Bounds with Kernel-Based Hypotheses</a></li>
<li><a href="#2-implication">(2) Implication:</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4-ranking-with-svms">4. Ranking with SVMs</a><ul>
<li><a href="#41-theoretical-guarantee">4.1 Theoretical Guarantee</a></li>
<li><a href="#42-objective-function-and-constraints">4.2 Objective Function and Constraints</a><ul>
<li><a href="#1-aim">(1) Aim:</a></li>
<li><a href="#2-objective-function">(2) Objective Function:</a></li>
<li><a href="#3-subject-to-the-constraints">(3) Subject to the Constraints:</a></li>
<li><a href="#4-interpretation">(4) Interpretation:</a></li>
<li><a href="#5-kernel-trick">(5) Kernel Trick:</a></li>
<li><a href="#6-application">(6) Application:</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#5-rankboost">5. RankBoost</a><ul>
<li><a href="#51-introduction">5.1 Introduction:</a></li>
<li><a href="#52-components">5.2 Components:</a><ul>
<li><a href="#1-base-rankers">(1) Base Rankers:</a></li>
<li><a href="#2-weak-learning-algorithm">(2) Weak Learning Algorithm:</a></li>
</ul>
</li>
<li><a href="#53-weighted-error-rate-epsilon_ts">5.3 Weighted error rate $\epsilon_{t}^{s}$</a><ul>
<li><a href="#1-meaning">(1) Meaning:</a></li>
<li><a href="#2-definition">(2) Definition:</a></li>
</ul>
</li>
<li><a href="#53-algorithm">5.3 Algorithm:</a><ul>
<li><a href="#1-pseudocode">(1) Pseudocode</a></li>
</ul>
</li>
<li><a href="#54-key-components">5.4 Key Components:</a><ul>
<li><a href="#1-base-ranker-selection">(1) Base Ranker Selection:</a></li>
<li><a href="#2-coefficient-alpha_t">(2) Coefficient $\alpha_t$:</a></li>
<li><a href="#3-distribution-update">(3) Distribution Update:</a></li>
</ul>
</li>
<li><a href="#55-explanation">5.5 Explanation:</a><ul>
<li><a href="#1-updates">(1) Updates:</a></li>
<li><a href="#2-final-hypothesis">(2) Final Hypothesis:</a></li>
<li><a href="#3-distribution-update-identity">(3) Distribution Update Identity:</a></li>
</ul>
</li>
<li><a href="#56-bound-on-the-empirical-error">5.6 Bound on the Empirical Error:</a><ul>
<li><a href="#1-theorem-103-empirical-error-bound-for-rankboost">(1) Theorem 10.3: Empirical Error Bound for RankBoost</a></li>
<li><a href="#2-proof">(2) Proof:</a></li>
<li><a href="#3-implications">(3) Implications:</a></li>
</ul>
</li>
<li><a href="#57-relationship-with-coordinate-descent">5.7 Relationship with Coordinate Descent:</a><ul>
<li><a href="#1-objective-function-f">(1) Objective Function $F$:</a></li>
<li><a href="#2-parameter-update-by-coordinate-descent">(2) Parameter Update by Coordinate Descent:</a></li>
<li><a href="#3-distribution-update-1">(3) Distribution Update:</a></li>
<li><a href="#4-directional-derivative-and-coordinate-descent">(4) Directional Derivative and Coordinate Descent:</a></li>
<li><a href="#5-step-size-eta">(5) Step Size $\eta$:</a></li>
<li><a href="#6-alternative-loss-functions">(6) Alternative Loss Functions:</a></li>
</ul>
</li>
<li><a href="#58-margin-bound-for-ensemble-methods-in-ranking">5.8 Margin Bound for Ensemble Methods in Ranking</a><ul>
<li><a href="#1-assumptions">(1) Assumptions:</a></li>
<li><a href="#2-corollary-104">(2) Corollary 10.4</a></li>
<li><a href="#3-applications">(3) Applications:</a></li>
<li><a href="#4-summary">(4) Summary:</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#6-bipartite-ranking">6. Bipartite ranking</a><ul>
<li><a href="#61-introduction">6.1 Introduction</a><ul>
<li><a href="#1-definition-1">(1) Definition</a></li>
<li><a href="#2-traditional-vs-bipartite-approach">(2) Traditional vs. Bipartite approach</a></li>
<li><a href="#3-learning-problem">(3) Learning problem</a></li>
<li><a href="#4-challenges">(4) Challenges</a></li>
</ul>
</li>
<li><a href="#62-boosting-in-bipartite-ranking">6.2 Boosting in bipartite ranking</a><ul>
<li><a href="#1-key-property-of-rankboost">(1) Key property of RankBoost</a></li>
<li><a href="#2-efficiency-in-bipartite-ranking">(2) Efficiency in bipartite ranking</a></li>
<li><a href="#3-pseudocode">(3) Pseudocode</a></li>
<li><a href="#4-relationship-with-adaboost">(4) Relationship with AdaBoost</a></li>
</ul>
</li>
<li><a href="#63-area-under-the-roc-curve">6.3 Area under the ROC curve</a><ul>
<li><a href="#1-definition-2">(1) Definition</a></li>
<li><a href="#2-properties-of-auc">(2) Properties of AUC</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#7-preference-based-setting">7. Preference-based setting</a><ul>
<li><a href="#71-introduction">7.1 Introduction</a><ul>
<li><a href="#1-comparison-with-score-based-setting">(1) Comparison with score-based setting</a></li>
<li><a href="#2-objective">(2) Objective</a></li>
<li><a href="#3-advantage">(3) Advantage</a></li>
<li><a href="#4-stages">(4) Stages</a></li>
</ul>
</li>
<li><a href="#72-second-stage-ranking-problem">7.2 Second-stage ranking problem</a><ul>
<li><a href="#1-assumption">(1) Assumption</a></li>
<li><a href="#2-stochastic-characteristics">(2) Stochastic characteristics</a></li>
<li><a href="#3-loss-function">(3) Loss function</a></li>
<li><a href="#4-expected-loss-and-regret">(4) Expected loss and regret</a></li>
<li><a href="#5-pairwise-independence">(5) Pairwise independence</a></li>
</ul>
</li>
<li><a href="#73-deterministic-algorithm">7.3 Deterministic algorithm</a><ul>
<li><a href="#1-sort-by-degree-algorithm">(1) Sort-by-degree algorithm</a></li>
<li><a href="#2-expected-loss-and-regret">(2) Expected loss and regret</a></li>
<li><a href="#3-implications-1">(3) Implications</a></li>
<li><a href="#4-theorem-105">(4) Theorem 10.5</a></li>
<li><a href="#5-limitations">(5) Limitations</a></li>
</ul>
</li>
<li><a href="#74-randomized-algorithm">7.4 Randomized algorithm</a><ul>
<li><a href="#1-introduction-1">（1） Introduction</a></li>
<li><a href="#2-algorithm">(2) Algorithm</a></li>
<li><a href="#3-guarantees">(3) Guarantees</a></li>
<li><a href="#4-time-complexity">(4) Time complexity</a></li>
</ul>
</li>
<li><a href="#75-extension-to-other-loss-functions">7.5 Extension to other loss functions</a><ul>
<li><a href="#1-weighted-loss-functions">(1) Weighted loss functions</a></li>
<li><a href="#2-weight-function-omega">(2) Weight function $\omega$</a></li>
<li><a href="#3-correct-order-importance">(3) Correct order importance</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#8-other-ranking-criteria">8. Other ranking criteria</a><ul>
<li><a href="#81-precision-precisionn-average-precision-recall">8.1 Precision, precision@n, average precision, recall</a><ul>
<li><a href="#1-precision">(1) Precision</a></li>
<li><a href="#2-precision-n">(2) Precision @n</a></li>
<li><a href="#3-average-precision">(3) Average precision</a></li>
<li><a href="#4-recall">(4) Recall</a></li>
</ul>
</li>
<li><a href="#82-dcg-and-ndcg">8.2 DCG and NDCG</a><ul>
<li><a href="#1-dcg">(1) DCG</a></li>
<li><a href="#2-ndcg">(2) NDCG</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><h2 id="1-1-Motivation-for-Ranking"><a href="#1-1-Motivation-for-Ranking" class="headerlink" title="1.1 Motivation for Ranking"></a>1.1 Motivation for Ranking</h2><h3 id="1-Resource-Limitation-in-Classification"><a href="#1-Resource-Limitation-in-Classification" class="headerlink" title="(1) Resource Limitation in Classification:"></a>(1) Resource Limitation in Classification:</h3><p>For large datasets, it’s often impractical to process all items labeled as relevant by a classifier. </p>
<h3 id="2-Examples"><a href="#2-Examples" class="headerlink" title="(2) Examples:"></a>(2) Examples:</h3><ul>
<li>Search engines</li>
<li>Fraud detection systems</li>
</ul>
<h2 id="1-2-Two-General-Settings-for-Ranking"><a href="#1-2-Two-General-Settings-for-Ranking" class="headerlink" title="1.2 Two General Settings for Ranking"></a>1.2 Two General Settings for Ranking</h2><p>(1) Score-Based Setting: Margin-based generalization bounds using Rademacher complexity</p>
<p>(2) Preference-Based Setting: Regret-based guarantees for both deterministic and randomized algorithms.</p>
<h2 id="1-3-Algorithms-Discussed"><a href="#1-3-Algorithms-Discussed" class="headerlink" title="1.3 Algorithms Discussed:"></a>1.3 Algorithms Discussed:</h2><h3 id="1-SVM-Based-Ranking-Algorithm"><a href="#1-SVM-Based-Ranking-Algorithm" class="headerlink" title="(1) SVM-Based Ranking Algorithm:"></a>(1) SVM-Based Ranking Algorithm:</h3><p>Derived from margin-based bounds</p>
<h3 id="2-RankBoost"><a href="#2-RankBoost" class="headerlink" title="(2) RankBoost:"></a>(2) RankBoost:</h3><p>A boosting algorithm specifically for ranking</p>
<h3 id="3-Bipartite-Ranking"><a href="#3-Bipartite-Ranking" class="headerlink" title="(3) Bipartite Ranking:"></a>(3) Bipartite Ranking:</h3><p>Classifying points into one of two classes and ranking</p>
<h2 id="1-4-Evaluation-Metrics"><a href="#1-4-Evaluation-Metrics" class="headerlink" title="1.4 Evaluation Metrics"></a>1.4 Evaluation Metrics</h2><p>ROC Curves and AUC</p>
<h1 id="2-The-Problem-of-Ranking"><a href="#2-The-Problem-of-Ranking" class="headerlink" title="2. The Problem of Ranking"></a>2. The Problem of Ranking</h1><h2 id="2-1-Ranking-Problem"><a href="#2-1-Ranking-Problem" class="headerlink" title="2.1 Ranking Problem"></a>2.1 Ranking Problem</h2><p>Using labeled information to create an accurate ranking prediction for all points in a dataset.<br>In the score-based setting, labeled information is provided only for pairs of points and the quality of the predictor is measured by its average pairwise misranking.</p>
<h2 id="2-2-Scoring-Function"><a href="#2-2-Scoring-Function" class="headerlink" title="2.2 Scoring Function"></a>2.2 Scoring Function</h2><p>Real-valued function assigning scores to input points</p>
<h2 id="2-3-Preference-Function-f"><a href="#2-3-Preference-Function-f" class="headerlink" title="2.3 Preference Function $f$"></a>2.3 Preference Function $f$</h2><h3 id="1-Definition"><a href="#1-Definition" class="headerlink" title="(1) Definition"></a>(1) Definition</h3><p>Let $X$ be the input space and $D$ be an unknown distribution over $X \times X$ indicating pairs of points the preference function $f: X \times X \to {-1, 0, +1}$.</p>
<h3 id="2-Non-Transitivity"><a href="#2-Non-Transitivity" class="headerlink" title="(2) Non-Transitivity"></a>(2) Non-Transitivity</h3><ul>
<li><p>Example:<br>$f(x, x’) &#x3D; 1$ and $f(x’, x’’) &#x3D; 1$ but $f(x, x’’) &#x3D; -1$ can all hold simultaneously.</p>
</li>
<li><p>Practice: This situation can arise in practice due to varying criteria for ranking different pairs of items.</p>
</li>
</ul>
<h2 id="2-4-Labeled-Sample"><a href="#2-4-Labeled-Sample" class="headerlink" title="2.4 Labeled Sample"></a>2.4 Labeled Sample</h2><p>The learner receives a labeled sample $S &#x3D; { ((x_1, x_1’), y_1), \ldots, ((x_m, x_m’), y_m) } \subset X \times X \times {-1, 0, +1}$ with $(x_i, x_i’)$ drawn i.i.d. according to $D$ and $y_i &#x3D; f(x_i, x_i’)$.</p>
<h2 id="2-5-Target"><a href="#2-5-Target" class="headerlink" title="2.5 Target"></a>2.5 Target</h2><h3 id="1-Goal"><a href="#1-Goal" class="headerlink" title="(1) Goal"></a>(1) Goal</h3><p>To select a hypothesis $h \in H$ with small expected pairwise misranking (empirical error) or generalization error $R(h)$.</p>
<h3 id="2-Generalization-Error-R-h"><a href="#2-Generalization-Error-R-h" class="headerlink" title="(2) Generalization Error $R(h)$"></a>(2) Generalization Error $R(h)$</h3><p>$$<br>R(h) &#x3D; \mathbb{P}_{(x, x’) \sim \mathcal{D}} \left[ \left( f(x, x’) \neq 0 \right) \land \left( f(x, x’)(h(x’) - h(x)) \leq 0 \right) \right]<br>$$</p>
<p>Measures the probability that $h$ misranks a pair $(x, x’)$.</p>
<h3 id="3-Empirical-Error-hat-R-S-h"><a href="#3-Empirical-Error-hat-R-S-h" class="headerlink" title="(3) Empirical Error $\hat{R}_S(h)$"></a>(3) Empirical Error $\hat{R}_S(h)$</h3><p>$$<br>\hat{R}<em>S(h) &#x3D; \frac{1}{m} \sum</em>{i&#x3D;1}^{m} \mathbf{1} \left[ (y_i \neq 0) \land \left( y_i (h(x_i’) - h(x_i)) \leq 0 \right) \right]<br>$$</p>
<p>Measures the misranking error of $h$ over the sample $S$.</p>
<h3 id="4-Key-points"><a href="#4-Key-points" class="headerlink" title="(4) Key points:"></a><strong>(4) Key points:</strong></h3><ul>
<li>The target preference function $f$ is generally non-transitive whereas the scoring function $h$ induces a transitive ordering.</li>
<li>This inherent difference means no hypothesis $h$ can perfectly predict the target pairwise ranking if $f$ is not transitive.</li>
<li>The empirical error is an estimate of the generalization error based on the sample data.</li>
</ul>
<h1 id="3-Generalization-Bound"><a href="#3-Generalization-Bound" class="headerlink" title="3. Generalization Bound"></a>3. Generalization Bound</h1><h2 id="3-1-Margin-Based-Generalization-Bounds"><a href="#3-1-Margin-Based-Generalization-Bounds" class="headerlink" title="3.1 Margin-Based Generalization Bounds"></a>3.1 Margin-Based Generalization Bounds</h2><h3 id="1-Simplification"><a href="#1-Simplification" class="headerlink" title="(1) Simplification:"></a>(1) Simplification:</h3><p>Pairwise labels are in ${-1, +1}$.</p>
<h3 id="2-Empirical-Margin-Loss"><a href="#2-Empirical-Margin-Loss" class="headerlink" title="(2) Empirical Margin Loss"></a>(2) Empirical Margin Loss</h3><p>$$<br>\hat{R}<em>{S, \rho}(h) &#x3D; \frac{1}{m} \sum</em>{i&#x3D;1}^{m} \Phi_{\rho}(y_i (h(x_i’) - h(x_i)))<br>$$</p>
<h3 id="3-Margin-Loss-and-Pairwise-Misranking"><a href="#3-Margin-Loss-and-Pairwise-Misranking" class="headerlink" title="(3) Margin Loss and Pairwise Misranking"></a>(3) Margin Loss and Pairwise Misranking</h3><p>$$<br>\hat{R}<em>{S, \rho}(h) \leq \frac{1}{m} \sum</em>{i&#x3D;1}^{m} \mathbf{1}_{y_i (h(x_i’) - h(x_i)) \leq \rho}<br>$$</p>
<h2 id="3-2-Theorem-10-1"><a href="#3-2-Theorem-10-1" class="headerlink" title="3.2 Theorem 10.1"></a>3.2 Theorem 10.1</h2><h3 id="1-Distribution-D"><a href="#1-Distribution-D" class="headerlink" title="(1) Distribution $D$"></a>(1) Distribution $D$</h3><ul>
<li>$D_1$: Marginal distribution of the first element of the pairs in $X \times X$.</li>
<li>$D_2$: Marginal distribution of the second element of the pairs.</li>
<li>Rademacher Complexity:</li>
</ul>
<p>$$<br>\mathfrak{R}_{m}^{\mathcal{D}<em>1}(\mathcal{H}) &#x3D; \mathfrak{R}</em>{m}^{\mathcal{D}_2}(\mathcal{H})<br>$$<br>If the $D$ is symmetric.</p>
<h3 id="2-Margin-Bound-for-Ranking"><a href="#2-Margin-Bound-for-Ranking" class="headerlink" title="(2) Margin Bound for Ranking"></a>(2) Margin Bound for Ranking</h3><p><strong>Theorem 10.1 (Margin bound for ranking)</strong> Let $\mathcal{H}$ be a set of real-valued functions. Fix $\rho &gt; 0$; then, for any $\delta &gt; 0$, with probability at least $1 - \delta$ over the choice of a sample $S$ of size $m$, each of the following holds for all $h \in \mathcal{H}$:</p>
<p>$$<br>R(h) \leq \hat{R}<em>{S, \rho}(h) + \frac{2}{\rho} \left( \mathfrak{R}</em>{m}^{\mathcal{D}<em>1}(\mathcal{H}) + \mathfrak{R}</em>{m}^{\mathcal{D}_2}(\mathcal{H}) \right) + \sqrt{\frac{\log \frac{1}{\delta}}{2m}} \quad (10.5)<br>$$</p>
<p>$$<br>R(h) \leq \hat{R}<em>{S, \rho}(h) + \frac{2}{\rho} \left( \hat{\mathfrak{R}}</em>{S_1}(\mathcal{H}) + \hat{\mathfrak{R}}_{S_2}(\mathcal{H}) \right) + 3\sqrt{\frac{\log \frac{2}{\delta}}{2m}} \quad (10.6)<br>$$</p>
<h3 id="3-Proof"><a href="#3-Proof" class="headerlink" title="(3) Proof:"></a>(3) Proof:</h3><ul>
<li>The proof is based on a comparison with the results of theorem 5.8.</li>
<li>The Rademacher complexity bounds are used to derive the margin-based generalization bounds.</li>
</ul>
<h3 id="4-Extension"><a href="#4-Extension" class="headerlink" title="(4) Extension:"></a>(4) Extension:</h3><ul>
<li><p>Motivation: How these bounds can be generalized uniformly for all values of the margin parameter $\rho &gt; 0$.</p>
</li>
<li><p>Additional Term: $\sqrt{\frac{\log \log_{2}(2&#x2F;\rho)}{m}}$,<br>accounting for the complexity introduced by varying $\rho$, ensuring that the bound holds uniformly.</p>
</li>
<li><p>Trade-off: Increasing $\rho$ can make the middle term smaller; it makes the first term larger.</p>
</li>
<li><p>Kernel-Based Hypotheses: Using known upper bounds for Rademacher complexity to derive explicit margin bounds for ranking.</p>
</li>
</ul>
<h2 id="3-3-Corollary-10-2"><a href="#3-3-Corollary-10-2" class="headerlink" title="3.3 Corollary 10.2"></a>3.3 Corollary 10.2</h2><h3 id="1-Margin-Bounds-with-Kernel-Based-Hypotheses"><a href="#1-Margin-Bounds-with-Kernel-Based-Hypotheses" class="headerlink" title="(1) Margin Bounds with Kernel-Based Hypotheses"></a>(1) Margin Bounds with Kernel-Based Hypotheses</h3><p><strong>Corollary 10.2 (Margin bounds for ranking with kernel-based hypotheses)</strong> Let $K: \mathcal{X} \times \mathcal{X} \to \mathbb{R}$ be a PDS kernel with $r &#x3D; \sup_{x \in \mathcal{X}} K(x, x)$. Let $\Phi: \mathcal{X} \to \mathcal{H}$ be a feature mapping associated to $K$ and let $\mathcal{H} &#x3D; { x \mapsto \mathbf{w} \cdot \Phi(x) : |\mathbf{w}|_{\mathcal{H}} \leq \Lambda }$ for some $\Lambda \geq 0$. Fix $\rho &gt; 0$. Then, for any $\delta &gt; 0$, the following pairwise margin bound holds with probability at least $1 - \delta$ for any $h \in \mathcal{H}$:</p>
<p>$$<br>R(h) \leq \hat{R}_{S, \rho}(h) + 4 \sqrt{\frac{r^2 \Lambda^2 &#x2F; \rho^2}{m}} + \sqrt{\frac{\log \frac{1}{\delta}}{2m}}. \quad (10.7)<br>$$</p>
<h3 id="2-Implication"><a href="#2-Implication" class="headerlink" title="(2) Implication:"></a>(2) Implication:</h3><ul>
<li>It depends only on the pairwise ranking margin and not directly on the dimension of the feature space.</li>
<li>It suggests that a small generalization error can be achieved when $\rho &#x2F; r$ is large even if the empirical margin loss is small.</li>
</ul>
<h1 id="4-Ranking-with-SVMs"><a href="#4-Ranking-with-SVMs" class="headerlink" title="4. Ranking with SVMs"></a>4. Ranking with SVMs</h1><h2 id="4-1-Theoretical-Guarantee"><a href="#4-1-Theoretical-Guarantee" class="headerlink" title="4.1 Theoretical Guarantee"></a>4.1 Theoretical Guarantee</h2><p>Proceeding as in section 5.4 for classification, the guarantee of corollary 10.2 can be expressed as follows: for any $\delta &gt; 0$, with probability at least $1 - \delta$, for all $h \in \mathcal{H} &#x3D; {x \mapsto \mathbf{w} \cdot \Phi(x) : |\mathbf{w}| \leq \Lambda }$,</p>
<p>$$<br>R(h) \leq \frac{1}{m} \sum_{i&#x3D;1}^{m} \xi_i + 4 \sqrt{\frac{r^2 \Lambda^2}{m}} + \sqrt{\frac{\log \frac{1}{\delta}}{2m}}, \quad (10.8)<br>$$</p>
<p>where $\xi_i &#x3D; \max \left( 1 - y_i \left[ \mathbf{w} \cdot \left( \Phi(x_i’) - \Phi(x_i) \right) \right], 0 \right)$ for all $i \in [m]$, and where $\Phi: \mathcal{X} \to \mathcal{H}$ is a feature mapping associated to a PDS kernel $K$.</p>
<h2 id="4-2-Objective-Function-and-Constraints"><a href="#4-2-Objective-Function-and-Constraints" class="headerlink" title="4.2 Objective Function and Constraints"></a>4.2 Objective Function and Constraints</h2><h3 id="1-Aim"><a href="#1-Aim" class="headerlink" title="(1) Aim:"></a>(1) Aim:</h3><p>To minimize the right-hand side of the above inequality which consists of:</p>
<ul>
<li>Minimizing the sum of slack variables $\xi_i$.</li>
<li>Minimizing $|w|^2$.</li>
</ul>
<h3 id="2-Objective-Function"><a href="#2-Objective-Function" class="headerlink" title="(2) Objective Function:"></a>(2) Objective Function:</h3><p>$$<br>\min_{\mathbf{w}, \xi} \frac{1}{2} |\mathbf{w}|^2 + C \sum_{i&#x3D;1}^{m} \xi_i<br>$$</p>
<h3 id="3-Subject-to-the-Constraints"><a href="#3-Subject-to-the-Constraints" class="headerlink" title="(3) Subject to the Constraints:"></a>(3) Subject to the Constraints:</h3><p>subject to:<br>$y_i \left[ \mathbf{w} \cdot \left( \Phi(x_i’) - \Phi(x_i) \right) \right] \geq 1 - \xi_i$<br>$\xi_i \geq 0, \quad \forall i \in [m]$.</p>
<h3 id="4-Interpretation"><a href="#4-Interpretation" class="headerlink" title="(4) Interpretation:"></a>(4) Interpretation:</h3><p>This problem is equivalent to the primal optimization problem of SVMs with a feature mapping $\Psi$: $\Psi(x, x’) &#x3D; \Phi(x’) - \Phi(x)$</p>
<h3 id="5-Kernel-Trick"><a href="#5-Kernel-Trick" class="headerlink" title="(5) Kernel Trick:"></a>(5) Kernel Trick:</h3><p>$$<br>K’_{ij} &#x3D; \Psi(x_i, x_i’) \cdot \Psi(x_j, x_j’) &#x3D; K(x_i, x_j) + K(x_i’, x_j’) - K(x_i’, x_j) - K(x_i, x_j’)<br>\quad (10.10)<br>$$</p>
<p>for all $i, j \in [m]$.</p>
<p>By using a PDS kernel $K$, the equivalent dual problem can be expressed.</p>
<h3 id="6-Application"><a href="#6-Application" class="headerlink" title="(6) Application:"></a>(6) Application:</h3><ul>
<li>This algorithm can be applied to the ranking problem in the score-based setting.</li>
<li>It can also be extended to cases where the labels are in ${-1, 0, +1}$.</li>
</ul>
<h1 id="5-RankBoost"><a href="#5-RankBoost" class="headerlink" title="5. RankBoost"></a>5. RankBoost</h1><h2 id="5-1-Introduction"><a href="#5-1-Introduction" class="headerlink" title="5.1 Introduction:"></a>5.1 Introduction:</h2><p>Boosting algorithm for pairwise ranking like AdaBoost algorithm.</p>
<h2 id="5-2-Components"><a href="#5-2-Components" class="headerlink" title="5.2 Components:"></a>5.2 Components:</h2><h3 id="1-Base-Rankers"><a href="#1-Base-Rankers" class="headerlink" title="(1) Base Rankers:"></a>(1) Base Rankers:</h3><p>Hypotheses returned by a weak learning algorithm for ranking.</p>
<h3 id="2-Weak-Learning-Algorithm"><a href="#2-Weak-Learning-Algorithm" class="headerlink" title="(2) Weak Learning Algorithm:"></a>(2) Weak Learning Algorithm:</h3><p>An algorithm that generates base hypotheses with minimal accuracy.</p>
<h2 id="5-3-Weighted-error-rate-epsilon-t-s"><a href="#5-3-Weighted-error-rate-epsilon-t-s" class="headerlink" title="5.3 Weighted error rate $\epsilon_{t}^{s}$"></a>5.3 Weighted error rate $\epsilon_{t}^{s}$</h2><h3 id="1-Meaning"><a href="#1-Meaning" class="headerlink" title="(1) Meaning:"></a>(1) Meaning:</h3><p>The weighted error rate of the base ranker at iteration $t$ for pairs that fall into a specific category $s$.</p>
<h3 id="2-Definition"><a href="#2-Definition" class="headerlink" title="(2) Definition:"></a>(2) Definition:</h3><p>$$<br>\epsilon_{t}^{s} &#x3D; \sum_{i&#x3D;1}^{m} D_{t}(i) \mathbf{1}<em>{y</em>{i}(h_{t}(x_{i}’) - h_{t}(x_{i})) &#x3D; s} &#x3D; \mathbb{E}<em>{i \sim D</em>{t}} \left[ \mathbf{1}<em>{y</em>{i}(h_{t}(x_{i}’) - h_{t}(x_{i})) &#x3D; s} \right]<br>$$</p>
<p>where $D_t(i)$ is the distribution weight of the $i$-th pair at iteration $t$.</p>
<h2 id="5-3-Algorithm"><a href="#5-3-Algorithm" class="headerlink" title="5.3 Algorithm:"></a>5.3 Algorithm:</h2><h3 id="1-Pseudocode"><a href="#1-Pseudocode" class="headerlink" title="(1) Pseudocode"></a>(1) Pseudocode</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">RankBoost($S = \&#123;(x_1, x_1&#x27;, y_1), \ldots, (x_m, x_m&#x27;, y_m)\&#125;$)</span><br><span class="line"></span><br><span class="line">for i &lt;- 1 to m do</span><br><span class="line">    D_1(i) &lt;- 1/m</span><br><span class="line"></span><br><span class="line">for t &lt;- 1 to T do</span><br><span class="line">    h_t &lt;- base ranker in H with smallest ε_t^- - ε_t^+</span><br><span class="line">    α_t &lt;- 1/2 log (ε_t^+/ε_t^-)</span><br><span class="line">    Z_t &lt;- ε_t^0 + 2(ε_t^+ ε_t^-)^1/2  // normalization factor</span><br><span class="line">    </span><br><span class="line">    for i &lt;- 1 to m do</span><br><span class="line">        D_&#123;t+1&#125;(i) &lt;- D_t(i) exp[-α_t y_i (h_t(x_i&#x27;) - h_t(x_i))] / Z_t</span><br><span class="line">    </span><br><span class="line">f &lt;- Σ_&#123;t=1&#125;^T α_t h_t</span><br><span class="line"></span><br><span class="line">return f</span><br></pre></td></tr></table></figure>

<h2 id="5-4-Key-Components"><a href="#5-4-Key-Components" class="headerlink" title="5.4 Key Components:"></a>5.4 Key Components:</h2><h3 id="1-Base-Ranker-Selection"><a href="#1-Base-Ranker-Selection" class="headerlink" title="(1) Base Ranker Selection:"></a>(1) Base Ranker Selection:</h3><p>At each iteration, select $h_t$ that minimizes $\epsilon_t^{-} - \epsilon_t^{+}$, focusing on the pair with the smallest pairwise misranking error: $h_t \in \arg\min_{h \in \mathcal{H}} \left{ - \mathbb{E}_{i \sim D_t} \left[ y_i \left( h(x_i’) - h(x_i) \right) \right] \right}$</p>
<h3 id="2-Coefficient-alpha-t"><a href="#2-Coefficient-alpha-t" class="headerlink" title="(2) Coefficient $\alpha_t$:"></a>(2) Coefficient $\alpha_t$:</h3><p>A function of the ratio of misranking accuracies.</p>
<h3 id="3-Distribution-Update"><a href="#3-Distribution-Update" class="headerlink" title="(3) Distribution Update:"></a>(3) Distribution Update:</h3><p>The distribution $D_t$ is updated to emphasize misranked pairs more in subsequent iterations.</p>
<h2 id="5-5-Explanation"><a href="#5-5-Explanation" class="headerlink" title="5.5 Explanation:"></a>5.5 Explanation:</h2><h3 id="1-Updates"><a href="#1-Updates" class="headerlink" title="(1) Updates:"></a>(1) Updates:</h3><p>If $\epsilon_t^- - \epsilon_t^+ &gt; 0$, then $\frac{\epsilon_t^+}{\epsilon_t^-} &lt; 1$ and $\alpha_t &gt; 0$, meaning the new distribution $D_{t+1}$ will increase the weight on misranked pairs and decrease the weight on correctly ranked pairs.</p>
<h3 id="2-Final-Hypothesis"><a href="#2-Final-Hypothesis" class="headerlink" title="(2) Final Hypothesis:"></a>(2) Final Hypothesis:</h3><p>After $T$ rounds of boosting, the final hypothesis $f$ is a linear combination of the base rankers:</p>
<p>$$<br>f &#x3D; \sum_{t&#x3D;1}^{T} \alpha_t h_t.<br>$$</p>
<h3 id="3-Distribution-Update-Identity"><a href="#3-Distribution-Update-Identity" class="headerlink" title="(3) Distribution Update Identity:"></a>(3) Distribution Update Identity:</h3><p>The distribution $D_{t+1}(i)$ can be expressed in terms of the final predictor $f_t$ and the normalization factors $Z_s$:</p>
<p>$$<br>D_{t+1}(i) &#x3D; \frac{e^{-y_i (f_t(x_i’) - f_t(x_i))}}{m \prod_{s&#x3D;1}^{t} Z_s}.<br>$$</p>
<h2 id="5-6-Bound-on-the-Empirical-Error"><a href="#5-6-Bound-on-the-Empirical-Error" class="headerlink" title="5.6 Bound on the Empirical Error:"></a>5.6 Bound on the Empirical Error:</h2><h3 id="1-Theorem-10-3-Empirical-Error-Bound-for-RankBoost"><a href="#1-Theorem-10-3-Empirical-Error-Bound-for-RankBoost" class="headerlink" title="(1) Theorem 10.3: Empirical Error Bound for RankBoost"></a>(1) Theorem 10.3: Empirical Error Bound for RankBoost</h3><p><strong>Theorem 10.3</strong> The empirical error of the hypothesis $h: \mathcal{X} \to {0,1}$ returned by RankBoost verifies:</p>
<p>$$<br>\hat{R}<em>S(h) \leq \exp \left[ -2 \sum</em>{t&#x3D;1}^{T} \left( \frac{\epsilon_t^+ - \epsilon_t^-}{2} \right)^2 \right]. \quad (10.13)<br>$$</p>
<p>Furthermore, if there exists $\gamma$ such that for all $t \in [T]$, $0 &lt; \gamma \leq \frac{\epsilon_t^+ - \epsilon_t^-}{2}$, then</p>
<p>$$<br>\hat{R}_S(h) \leq \exp(-2 \gamma^2 T). \quad (10.14)<br>$$</p>
<h3 id="2-Proof"><a href="#2-Proof" class="headerlink" title="(2) Proof:"></a>(2) Proof:</h3><ul>
<li>General Inequality:</li>
</ul>
<p>$$<br>\mathbf{1}_{u \leq 0} \leq \exp(-u) \text{ for all } u \in \mathbb{R} \text{ and identity 10.12}:<br>$$</p>
<p>$$<br>\hat{R}<em>S(h) &#x3D; \frac{1}{m} \sum</em>{i&#x3D;1}^{m} \mathbf{1}<em>{y_i (f_T(x_i’) - f_T(x_i)) \leq 0} \leq \frac{1}{m} \sum</em>{i&#x3D;1}^{m} \exp \left( -y_i (f_T(x_i’) - f_T(x_i)) \right).<br>$$</p>
<ul>
<li>Expression of $Z_t$:</li>
</ul>
<p>$$<br>\hat{R}<em>S(h) \leq \frac{1}{m} \sum</em>{i&#x3D;1}^{m} \prod_{t&#x3D;1}^{T} Z_t &#x3D; \prod_{t&#x3D;1}^{T} Z_t.<br>$$</p>
<ul>
<li>Definition and Upper Bound of $Z_t$:</li>
</ul>
<p>$$<br>Z_t &#x3D; \epsilon_t^+ e^{-\alpha_t} + \epsilon_t^- e^{\alpha_t} + \epsilon_t^0<br>$$</p>
<p>By using the simplification and convexity of the square root function:</p>
<p>$$<br>Z_t \leq \exp \left( - \left( \frac{\epsilon_t^+ - \epsilon_t^-}{2} \right)^2 \right).<br>$$</p>
<ul>
<li>Assumption:</li>
</ul>
<p>If there exists $\gamma$ such that $0 &lt; \gamma \leq \frac{\epsilon_t^+ - \epsilon_t^-}{2}$, then:</p>
<p>$$<br>\prod_{t&#x3D;1}^{T} Z_t \leq \exp(-2 \gamma^2 T).<br>$$</p>
<h3 id="3-Implications"><a href="#3-Implications" class="headerlink" title="(3) Implications:"></a>(3) Implications:</h3><ul>
<li><p>Empirical Error:<br>The empirical error decreases exponentially with the boosting rounds $T$.</p>
</li>
<li><p>Edge Condition:<br>The bound assumes that the difference of each base ranker is lower bounded by a positive value $\gamma &gt; 0$.</p>
</li>
<li><p>Weak Ranking Assumption:</p>
</li>
</ul>
<p>The assumption $\gamma \leq \frac{\epsilon_t^+ - \epsilon_t^-}{2}$ can be relaxed to $\gamma \leq \frac{\epsilon_t^+ - \epsilon_t^-}{\sqrt{\epsilon_t^+ + \epsilon_t^-}}$,</p>
<p>which considers the normalized relative difference.</p>
<ul>
<li><p>Coefficient $\alpha_t$:<br>It is chosen to minimize $Z_t$.</p>
</li>
<li><p>Base Ranker Selection:<br>Base ranker can be selected based on other criteria like minimal error on the distribution $D_t$.</p>
</li>
<li><p>Range of Base Rankers:<br>The base rankers could have a broader range.</p>
</li>
</ul>
<h2 id="5-7-Relationship-with-Coordinate-Descent"><a href="#5-7-Relationship-with-Coordinate-Descent" class="headerlink" title="5.7 Relationship with Coordinate Descent:"></a>5.7 Relationship with Coordinate Descent:</h2><h3 id="1-Objective-Function-F"><a href="#1-Objective-Function-F" class="headerlink" title="(1) Objective Function $F$:"></a>(1) Objective Function $F$:</h3><p>$$<br>F(\alpha) &#x3D; \sum_{i&#x3D;1}^{m} e^{-y_i [f_N(x_i’) - f_N(x_i)]} &#x3D; \sum_{i&#x3D;1}^{m} e^{-y_i \sum_{j&#x3D;1}^{N} \alpha_j [h_j(x_i’) - h_j(x_i)]},<br>$$<br>A convex upper bound on the zero-one pairwise loss function.</p>
<h3 id="2-Parameter-Update-by-Coordinate-Descent"><a href="#2-Parameter-Update-by-Coordinate-Descent" class="headerlink" title="(2) Parameter Update by Coordinate Descent:"></a>(2) Parameter Update by Coordinate Descent:</h3><ul>
<li><p>The parameter vector after iteration $t$ is given by $\alpha_t &#x3D; \alpha_{t-1} + \eta e_k$, where $e_k$ is the unit vector corresponding to the $k$-th coordinate in $\mathbb{R}^N$.</p>
</li>
<li><p>The function $f_t$ is the linear combination of base hypotheses $h_j$ up to iteration $t$:</p>
</li>
</ul>
<p>$$<br>f_t &#x3D; \sum_{j&#x3D;1}^{t} \alpha_j h_j.<br>$$</p>
<h3 id="3-Distribution-Update-1"><a href="#3-Distribution-Update-1" class="headerlink" title="(3) Distribution Update:"></a>(3) Distribution Update:</h3><p>The distribution $D_{t+1}$ over the indices ${1, \ldots, m}$ is updated as:</p>
<p>$$<br>D_{t+1}(i) &#x3D; \frac{e^{-y_i (f_t(x_i’) - f_t(x_i))}}{m \prod_{s&#x3D;1}^{t} Z_s},<br>$$</p>
<p>where $Z_s$ is the normalization factor ensuring that $D_{t+1}$ sums to 1.</p>
<h3 id="4-Directional-Derivative-and-Coordinate-Descent"><a href="#4-Directional-Derivative-and-Coordinate-Descent" class="headerlink" title="(4) Directional Derivative and Coordinate Descent:"></a>(4) Directional Derivative and Coordinate Descent:</h3><p>At each iteration $t \geq 1$, the direction $e_k$ selected by coordinate descent minimizes the directional derivative $F’(\alpha_{t-1}, e_k)$:</p>
<p>$$<br>F’(\alpha_{t-1}, e_k) &#x3D; \lim_{\eta \to 0} \frac{F(\alpha_{t-1} + \eta e_k) - F(\alpha_{t-1})}{\eta}.<br>$$</p>
<p>The directional derivative is expressed as:</p>
<p>$$<br>F’(\alpha_{t-1}, e_k) &#x3D; - \left[ \epsilon_t^- - \epsilon_t^+ \right] \prod_{s&#x3D;1}^{t-1} Z_s.<br>$$</p>
<h3 id="5-Step-Size-eta"><a href="#5-Step-Size-eta" class="headerlink" title="(5) Step Size $\eta$:"></a>(5) Step Size $\eta$:</h3><p>The step size $\eta$ is chosen to minimize $F(\alpha_{t-1} + \eta e_k)$. Setting the derivative with respect to $\eta$ to zero:</p>
<p>$$<br>\frac{d}{d\eta} F(\alpha_{t-1} + \eta e_k) &#x3D; 0.<br>$$</p>
<p>This results in:</p>
<p>$$<br>\eta &#x3D; \frac{1}{2} \log \frac{\epsilon_t^+}{\epsilon_t^-}.<br>$$</p>
<h3 id="6-Alternative-Loss-Functions"><a href="#6-Alternative-Loss-Functions" class="headerlink" title="(6) Alternative Loss Functions:"></a>(6) Alternative Loss Functions:</h3><p>Other convex loss functions can be used to upper bound the zero-one pairwise misranking loss, such as the logistic loss:</p>
<p>$$<br>\alpha \mapsto \sum_{i&#x3D;1}^{m} \log(1 + e^{-y_i (f_N(x_i’) - f_N(x_i))}),<br>$$</p>
<p>which can lead to alternative boosting-type algorithms.</p>
<h2 id="5-8-Margin-Bound-for-Ensemble-Methods-in-Ranking"><a href="#5-8-Margin-Bound-for-Ensemble-Methods-in-Ranking" class="headerlink" title="5.8 Margin Bound for Ensemble Methods in Ranking"></a>5.8 Margin Bound for Ensemble Methods in Ranking</h2><h3 id="1-Assumptions"><a href="#1-Assumptions" class="headerlink" title="(1) Assumptions:"></a>(1) Assumptions:</h3><ul>
<li>The pairwise labels are assumed to be in ${-1, +1}$.</li>
<li>By lemma 7.4, the empirical Rademacher complexity of the convex hull $\text{conv}(H)$ equals that of $H$.</li>
</ul>
<h3 id="2-Corollary-10-4"><a href="#2-Corollary-10-4" class="headerlink" title="(2) Corollary 10.4"></a>(2) Corollary 10.4</h3><p><strong>Corollary 10.4</strong> Let $\mathcal{H}$ be a set of real-valued functions. Fix $\rho &gt; 0$; then, for any $\delta &gt; 0$, with probability at least $1 - \delta$ over the choice of a sample $S$ of size $m$, each of the following ranking guarantees holds for all $h \in \text{conv}(\mathcal{H})$:</p>
<p>$$<br>R(h) \leq \hat{R}<em>{S, \rho}(h) + \frac{2}{\rho} \left( \mathfrak{R}</em>{m}^{\mathcal{D}<em>1}(\mathcal{H}) + \mathfrak{R}</em>{m}^{\mathcal{D}_2}(\mathcal{H}) \right) + \sqrt{\frac{\log \frac{1}{\delta}}{2m}}. \quad (10.17)<br>$$</p>
<p>$$<br>R(h) \leq \hat{R}<em>{S, \rho}(h) + \frac{2}{\rho} \left( \hat{\mathfrak{R}}</em>{S_1}(\mathcal{H}) + \hat{\mathfrak{R}}_{S_2}(\mathcal{H}) \right) + 3 \sqrt{\frac{\log \frac{2}{\delta}}{2m}}. \quad (10.18)<br>$$</p>
<h3 id="3-Applications"><a href="#3-Applications" class="headerlink" title="(3) Applications:"></a>(3) Applications:</h3><p>For RankBoost, these bounds apply to $f &#x2F; | \alpha |_1$, where $f$ is the hypothesis returned by the algorithm. Since $f$ and $f &#x2F; | \alpha |_1$ induce the same ordering of the points, for any $\delta &gt; 0$, the following holds with probability at least $1 - \delta$:</p>
<p>$$<br>R(f) \leq \hat{R}_{S, \rho}(f &#x2F; | \alpha |<em>1) + \frac{2}{\rho} \left( \mathfrak{R}</em>{m}^{\mathcal{D}<em>1}(\mathcal{H}) + \mathfrak{R}</em>{m}^{\mathcal{D}_2}(\mathcal{H}) \right) + \sqrt{\frac{\log \frac{1}{\delta}}{2m}}. \quad (10.19)<br>$$</p>
<h3 id="4-Summary"><a href="#4-Summary" class="headerlink" title="(4) Summary:"></a>(4) Summary:</h3><ul>
<li><p>Number of Boosting Rounds: The bound is independent of the number of boosting iterations.</p>
</li>
<li><p>Dependencies of Bound:<br>i. The margin $\rho$; ii. The sample size $m$; iii. The Rademacher complexity of the family of base classifiers $H$.</p>
</li>
<li><p>Effective Generalization:<br>The bounds ensure effective generalization if the pairwise margin loss is small for a sufficiently large margin $\rho$.</p>
</li>
</ul>
<h1 id="6-Bipartite-ranking"><a href="#6-Bipartite-ranking" class="headerlink" title="6. Bipartite ranking"></a>6. Bipartite ranking</h1><h2 id="6-1-Introduction"><a href="#6-1-Introduction" class="headerlink" title="6.1 Introduction"></a>6.1 Introduction</h2><h3 id="1-Definition-1"><a href="#1-Definition-1" class="headerlink" title="(1) Definition"></a>(1) Definition</h3><ul>
<li><p>Bipartite ranking problem: In this scenario, the set of points is partitioned into two classes: the class of positive points &amp; the class of negative points.</p>
</li>
<li><p>Goal: To rank positive points higher than negative points.</p>
</li>
</ul>
<h3 id="2-Traditional-vs-Bipartite-approach"><a href="#2-Traditional-vs-Bipartite-approach" class="headerlink" title="(2) Traditional vs. Bipartite approach"></a>(2) Traditional vs. Bipartite approach</h3><ul>
<li><p>Traditional: The learner receives a sample of random pairs</p>
</li>
<li><p>Bipartite ranking: The learner receives two separate samples</p>
</li>
</ul>
<h3 id="3-Learning-problem"><a href="#3-Learning-problem" class="headerlink" title="(3) Learning problem"></a>(3) Learning problem</h3><ul>
<li>Generalization error</li>
</ul>
<p>$$<br>R(h) &#x3D; \mathbb{P}<em>{x’ \sim \mathcal{D}</em>+, x \sim \mathcal{D}_-} [h(x’) &lt; h(x)].<br>$$</p>
<ul>
<li>Empirical error</li>
</ul>
<p>$$<br>\hat{R}<em>{S</em>+, S_-}(h) &#x3D; \frac{1}{mn} \sum_{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{n} \mathbf{1}_{h(x_j) &lt; h(x_i’)}.<br>$$</p>
<h3 id="4-Challenges"><a href="#4-Challenges" class="headerlink" title="(4) Challenges"></a>(4) Challenges</h3><ul>
<li><p>Complexity: Requires dealing with $mn$ pairs</p>
</li>
<li><p>Differences from binary classification: Differs in objectives and measures of success</p>
</li>
</ul>
<h2 id="6-2-Boosting-in-bipartite-ranking"><a href="#6-2-Boosting-in-bipartite-ranking" class="headerlink" title="6.2 Boosting in bipartite ranking"></a>6.2 Boosting in bipartite ranking</h2><h3 id="1-Key-property-of-RankBoost"><a href="#1-Key-property-of-RankBoost" class="headerlink" title="(1) Key property of RankBoost"></a>(1) Key property of RankBoost</h3><ul>
<li><p>Objective function: Bbased on the exponential function</p>
</li>
<li><p>Distribution decomposition: The product of two distributions</p>
</li>
</ul>
<h3 id="2-Efficiency-in-bipartite-ranking"><a href="#2-Efficiency-in-bipartite-ranking" class="headerlink" title="(2) Efficiency in bipartite ranking"></a>(2) Efficiency in bipartite ranking</h3><p>The time and space complexity depends only on the total number of points $m+n$, not on the number of pairs $m \times n$.</p>
<h3 id="3-Pseudocode"><a href="#3-Pseudocode" class="headerlink" title="(3) Pseudocode"></a>(3) Pseudocode</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">BipartiteRankBoost($S = \&#123;x_1&#x27;, \ldots, x_m&#x27;, x_1, \ldots, x_n\&#125;$)</span><br><span class="line"></span><br><span class="line">for j &lt;- 1 to m do</span><br><span class="line">    $D_+^1(j) \leftarrow \frac&#123;1&#125;&#123;m&#125;$</span><br><span class="line"></span><br><span class="line">for i &lt;- 1 to n do</span><br><span class="line">    $D_-^1(i) \leftarrow \frac&#123;1&#125;&#123;n&#125;$</span><br><span class="line"></span><br><span class="line">for t &lt;- 1 to T do</span><br><span class="line">    $h_t \leftarrow$ base ranker in $\mathcal&#123;H&#125;$ with smallest $\epsilon_t^- - \epsilon_t^+ = \mathbb&#123;E&#125;_&#123;j \sim D_+^t&#125;[h(x_j)] - \mathbb&#123;E&#125;_&#123;i \sim D_-^t&#125;[h(x_i)]$</span><br><span class="line">    $\alpha_t \leftarrow \frac&#123;1&#125;&#123;2&#125; \log \frac&#123;\epsilon_t^+&#125;&#123;\epsilon_t^-&#125;$</span><br><span class="line">    $Z_t^+ \leftarrow 1 - \epsilon_t^+ + \sqrt&#123;\epsilon_t^+ \epsilon_t^-&#125;$</span><br><span class="line">    </span><br><span class="line">    for i &lt;- 1 to n do</span><br><span class="line">        $D_+^&#123;t+1&#125;(i) \leftarrow D_+^t(i) \exp \left[ -\alpha_t h_t(x_i) \right] / Z_t^+$</span><br><span class="line">        </span><br><span class="line">    $Z_t^- \leftarrow 1 - \epsilon_t^- + \sqrt&#123;\epsilon_t^+ \epsilon_t^-&#125;$</span><br><span class="line">    </span><br><span class="line">    for j &lt;- 1 to m do</span><br><span class="line">        $D_-^&#123;t+1&#125;(j) \leftarrow D_-^t(j) \exp \left[ +\alpha_t h_t(x_j) \right] / Z_t^-$</span><br><span class="line">        </span><br><span class="line">$f \leftarrow \sum_&#123;t=1&#125;^&#123;T&#125; \alpha_t h_t$</span><br><span class="line"></span><br><span class="line">return f</span><br></pre></td></tr></table></figure>

<h3 id="4-Relationship-with-AdaBoost"><a href="#4-Relationship-with-AdaBoost" class="headerlink" title="(4) Relationship with AdaBoost"></a>(4) Relationship with AdaBoost</h3><ul>
<li>Objective function</li>
</ul>
<p>The objective function of RankBoost can be expressed as:</p>
<p>$$<br>F_{\text{RankBoost}}(\alpha) &#x3D; \sum_{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{n} \exp[-(f(x_i’) - f(x_j))].<br>$$</p>
<p>This can be decomposed into:</p>
<p>$$<br>F_{\text{RankBoost}}(\alpha) &#x3D; F_+(\alpha) F_-(\alpha),<br>$$</p>
<p>  where $F_+$ is the sum over positive points and $F_-$ is the sum over negative points.</p>
<p>Similarly, the objective function of AdaBoost can be expressed as:</p>
<p>$$<br>F_{\text{AdaBoost}}(\alpha) &#x3D; F_+(\alpha) + F_-(\alpha).<br>$$</p>
<ul>
<li>Connection</li>
</ul>
<p>The gradient of the RankBoost objective function can be expressed in terms of the gradient of the AdaBoost objective function:</p>
<p>$$<br>\nabla_{\alpha} F_{\text{RankBoost}}(\alpha) &#x3D; F_-(\alpha) \nabla_{\alpha} F_+(\alpha) + F_+(\alpha) \nabla_{\alpha} F_-(\alpha).<br>$$</p>
<p>If $\alpha$ minimizes $F_{\text{AdaBoost}}$, then $\nabla_{\alpha} F_{\text{RankBoost}}(\alpha) &#x3D; 0$, implying $\alpha$ also minimizes the convex function associated with RankBoost.</p>
<ul>
<li>Empirical performance: It is observed empirically to be faster in convergence than AdaBoost.</li>
</ul>
<h2 id="6-3-Area-under-the-ROC-curve"><a href="#6-3-Area-under-the-ROC-curve" class="headerlink" title="6.3 Area under the ROC curve"></a>6.3 Area under the ROC curve</h2><h3 id="1-Definition-2"><a href="#1-Definition-2" class="headerlink" title="(1) Definition"></a>(1) Definition</h3><ul>
<li><p>AUC: Measures the performance of a ranking function by summarizing the trade-off between true positive rates and false positive rates across different thresholds.</p>
</li>
<li><p>Pairwise misranking: The proportion of incorrectly ranked pairs $\hat{R}(h, U) &#x3D; \frac{1}{mn} \sum_{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{n} \mathbf{1}_{h(z_i’) &lt; h(z_j)}.$</p>
</li>
<li><p>AUC calculation: Representing the average pairwise ranking accuracy</p>
</li>
<li><p>ROC curve: The ROC curve plots the true positive rate (TPR) against the false positive rate (FPR)</p>
</li>
<li><p>Construction of ROC curve: Points on the ROC curve are generated by varying a threshold value $\theta$. At one extreme, all points are predicted as negatives, and at the other, all as positives.</p>
</li>
</ul>
<h3 id="2-Properties-of-AUC"><a href="#2-Properties-of-AUC" class="headerlink" title="(2) Properties of AUC"></a>(2) Properties of AUC</h3><ul>
<li><p>Metrics: Higher AUC values indicate better ranking performance. An AUC of 1 means perfect ranking, while an AUC of 0.5 suggests random ranking.</p>
</li>
<li><p>Computational complexity: i. Linear time calculation from a sorted array, given by $r&#x2F;(mn)$; ii. The overall computational complexity is $O((m+n)\log(m+n))$ assuming a comparison-based sorting algorithm.</p>
</li>
</ul>
<h1 id="7-Preference-based-setting"><a href="#7-Preference-based-setting" class="headerlink" title="7. Preference-based setting"></a>7. Preference-based setting</h1><h2 id="7-1-Introduction"><a href="#7-1-Introduction" class="headerlink" title="7.1 Introduction"></a>7.1 Introduction</h2><h3 id="1-Comparison-with-score-based-setting"><a href="#1-Comparison-with-score-based-setting" class="headerlink" title="(1) Comparison with score-based setting"></a>(1) Comparison with score-based setting</h3><ul>
<li>In the score-based setting, the goal is to provide a linear order for all points in $X$</li>
<li>The preference-based setting simplifies the task by focusing only on ranking the query subset.</li>
</ul>
<h3 id="2-Objective"><a href="#2-Objective" class="headerlink" title="(2) Objective"></a>(2) Objective</h3><p>The goal is to rank a finite query subset as accurately as possible</p>
<h3 id="3-Advantage"><a href="#3-Advantage" class="headerlink" title="(3) Advantage"></a>(3) Advantage</h3><p>Unlike the score-based setting, the learning algorithm is not required to return a linear ordering of all points, which can be challenging due to non-transitive pairwise preference labeling.</p>
<h3 id="4-Stages"><a href="#4-Stages" class="headerlink" title="(4) Stages"></a>(4) Stages</h3><ul>
<li>First stage: learning the preference function</li>
</ul>
<ol>
<li>A sample of labeled pairs $S$ is used to learn a preference function  </li>
<li>The preference function can be obtained using a standard classification algorithm trained on $S$  </li>
<li>$h$ is not required to induce a linear ordering</li>
</ol>
<ul>
<li>Second stage: ranking query subset</li>
</ul>
<ol>
<li>Given a query subset $X’ \subseteq X$, the preference function $h$ is used to determine a ranking of $X’$.</li>
<li>Generate an accurate ranking for the query subset.</li>
<li>The complexity of the algorithm that determines the ranking is measured by the number of calls to $h$.</li>
</ol>
<h2 id="7-2-Second-stage-ranking-problem"><a href="#7-2-Second-stage-ranking-problem" class="headerlink" title="7.2 Second-stage ranking problem"></a>7.2 Second-stage ranking problem</h2><h3 id="1-Assumption"><a href="#1-Assumption" class="headerlink" title="(1) Assumption"></a>(1) Assumption</h3><p>Pairwise consistent: $h(u,v) + h(v,u) &#x3D; 1$ for all $u,v \in X$</p>
<h3 id="2-Stochastic-characteristics"><a href="#2-Stochastic-characteristics" class="headerlink" title="(2) Stochastic characteristics"></a>(2) Stochastic characteristics</h3><ul>
<li><p>Unknown Distribution $D$: Pairs $(X, \sigma^*)$ are drawn from an unknown distribution, where $X \subseteq X$ is a query subset and $\sigma^*$ is a target ranking or permutation of $X$.</p>
</li>
<li><p>Objective: Use the preference function $h$ to return an accurate ranking $A(X)$ that approximates $\sigma^*$.</p>
</li>
</ul>
<h3 id="3-Loss-function"><a href="#3-Loss-function" class="headerlink" title="(3) Loss function"></a>(3) Loss function</h3><ul>
<li>Loss function $L$</li>
</ul>
<p>$$<br>L(\sigma, \sigma^*) &#x3D; \frac{2}{n(n - 1)} \sum_{u \neq v} \mathbf{1}<em>{\sigma(u) &lt; \sigma(v)} \mathbf{1}</em>{\sigma^*(v) &lt; \sigma^*(u)},<br>$$<br>where the sum runs over all pairs $(u, v)$ with distinct elements of $X$.</p>
<ul>
<li>Preference Function Loss $L(h, \sigma^*)$<br>$$L(h, \sigma^) &#x3D; \frac{2}{n(n - 1)} \sum_{u \neq v} h(u, v) \mathbf{1}_{\sigma^(v) &lt; \sigma^*(u)}.$$</li>
</ul>
<h3 id="4-Expected-loss-and-regret"><a href="#4-Expected-loss-and-regret" class="headerlink" title="(4) Expected loss and regret"></a>(4) Expected loss and regret</h3><ul>
<li>Expected loss:</li>
</ul>
<p>For a deterministic algorithm $A$, the expected loss is</p>
<p>$$<br>\mathbb{E}_{(X, \sigma^*) \sim \mathcal{D}} [L(A(X), \sigma^*)].<br>$$</p>
<ul>
<li>Regret of algorithm $A$:<br>Defined as the difference between its loss and that of the best fixed global ranking:</li>
</ul>
<p>$$<br>\text{Reg}(A) &#x3D; \mathbb{E}<em>{(X, \sigma^*) \sim \mathcal{D}} [L(A(X), \sigma^*)] - \min</em>{\sigma’} \mathbb{E}_{(X, \sigma^*) \sim \mathcal{D}} [L(\sigma’, \sigma^*)].<br>$$</p>
<ul>
<li>Regret of preference function $h$:</li>
</ul>
<p>$$<br>\text{Reg}(h) &#x3D; \mathbb{E}<em>{(X, \sigma^*) \sim \mathcal{D}} [L(h | X, \sigma^*)] - \min</em>{h’} \mathbb{E}_{(X, \sigma^*) \sim \mathcal{D}} [L(h’ | X, \sigma^*)],<br>$$<br>where $h | X$ denotes the restriction of $h$ to $X \times X$.</p>
<h3 id="5-Pairwise-independence"><a href="#5-Pairwise-independence" class="headerlink" title="(5) Pairwise independence"></a>(5) Pairwise independence</h3><ul>
<li>Assumes that for any $u,v \in X$, and any two sets $X_1$ and $X_2$ containing $u$ and $v$, the random variable $\sigma^* \mid X$ conditioned on $X$ maintains independence between pairs.</li>
<li>Helps in defining and analyzing the regret for the ranking algorithms.</li>
</ul>
<h2 id="7-3-Deterministic-algorithm"><a href="#7-3-Deterministic-algorithm" class="headerlink" title="7.3 Deterministic algorithm"></a>7.3 Deterministic algorithm</h2><h3 id="1-Sort-by-degree-algorithm"><a href="#1-Sort-by-degree-algorithm" class="headerlink" title="(1) Sort-by-degree algorithm"></a>(1) Sort-by-degree algorithm</h3><p>A deterministic approach that ranks elements based on how many other elements they are preferred to.</p>
<h3 id="2-Expected-loss-and-regret"><a href="#2-Expected-loss-and-regret" class="headerlink" title="(2) Expected loss and regret"></a>(2) Expected loss and regret</h3><p>$$<br>\mathbb{E}<em>{X, \sigma^*} [L(A</em>{\text{sort-by-degree}}(X), \sigma^*)] \leq 2 \mathbb{E}_{X, \sigma^*} [L(h, \sigma^*)].<br>$$</p>
<p>$$<br>\text{Reg}(A_{\text{sort-by-degree}}(X)) \leq 2 \text{Reg}(h).<br>$$</p>
<h3 id="3-Implications-1"><a href="#3-Implications-1" class="headerlink" title="(3) Implications"></a>(3) Implications</h3><ul>
<li>The algorithm can achieve an accurate ranking when the loss or regret of the preference function is small.</li>
<li>These bounds connect the ranking loss or regret of the algorithm to the classification loss or regret of $h$.</li>
</ul>
<h3 id="4-Theorem-10-5"><a href="#4-Theorem-10-5" class="headerlink" title="(4) Theorem 10.5"></a>(4) Theorem 10.5</h3><p><strong>Theorem 10.5 (Lower bound for deterministic algorithms)</strong> For any deterministic algorithm $A$, there is a bipartite distribution for which</p>
<p>$$<br>\text{Reg}(A) \geq 2 \text{Reg}(h).<br>$$</p>
<p>No deterministic algorithm can improve upon the factor of two in the regret guarantee</p>
<h3 id="5-Limitations"><a href="#5-Limitations" class="headerlink" title="(5) Limitations"></a>(5) Limitations</h3><ul>
<li><p>Factor of two:<br>The performance is at most twice as bad as the best possible.</p>
</li>
<li><p>Example:<br>For a binary classifier with an error rate of 25%, the worst-case pairwise misranking error for the ranking algorithm would be at most 50%.</p>
</li>
<li><p>Randomization:<br>Randomization is suggested as deterministic algorithms have an inherent lower bound on performance.</p>
</li>
</ul>
<h2 id="7-4-Randomized-algorithm"><a href="#7-4-Randomized-algorithm" class="headerlink" title="7.4 Randomized algorithm"></a>7.4 Randomized algorithm</h2><h3 id="（1）-Introduction"><a href="#（1）-Introduction" class="headerlink" title="（1） Introduction"></a>（1） Introduction</h3><ul>
<li><p>General idea： Extends the QuickSort algorithm for the second stage of ranking</p>
</li>
<li><p>Advantage： The expected time complexity is $O(n \log n)$ when applied to an array of size $n$, and it removes the factor of two in the deterministic case bounds.</p>
</li>
</ul>
<h3 id="2-Algorithm"><a href="#2-Algorithm" class="headerlink" title="(2) Algorithm"></a>(2) Algorithm</h3><ul>
<li><p>Pivot selection:<br>At each recursive step, a pivot element $u$ is selected uniformly at random from $X$</p>
</li>
<li><p>Partitioning:</p>
</li>
</ul>
<p>For each $v \neq u$:</p>
<ol>
<li>Place $v$ on the left of $u$ with probability $h(v,u)$.</li>
<li>Place $v$ on the right of $u$ with probability $h(u,v)$.</li>
</ol>
<ul>
<li><p>Recursion: The algorithm proceeds recursively with the left and right subarrays.</p>
</li>
<li><p>Concatenation:<br>The final permutation is obtained by concatenating the results of the left recursion, $u$, and the right recursion.</p>
</li>
</ul>
<h3 id="3-Guarantees"><a href="#3-Guarantees" class="headerlink" title="(3) Guarantees"></a>(3) Guarantees</h3><ul>
<li>Expected Loss</li>
</ul>
<p>$$<br>\mathbb{E}<em>{X, \sigma^*, s} [L(A</em>{\text{QuickSort}}(X, s), \sigma^*)] &#x3D; \mathbb{E}_{X, \sigma^*} [L(h, \sigma^*)].<br>$$</p>
<ul>
<li>Regret</li>
</ul>
<p>$$<br>\text{Reg}(A_{\text{QuickSort}}) \leq \text{Reg}(h).<br>$$</p>
<ul>
<li>General Ranking Setting</li>
</ul>
<p>$$<br>\mathbb{E}<em>{X, \sigma^*, s} [L(A</em>{\text{QuickSort}}(X, s), \sigma^*)] \leq 2 \mathbb{E}_{X, \sigma^*} [L(h, \sigma^*)].<br>$$</p>
<ul>
<li>Implication: The expected loss for QuickSort matches the loss of the preference function $h$ without the factor of two</li>
</ul>
<h3 id="4-Time-complexity"><a href="#4-Time-complexity" class="headerlink" title="(4) Time complexity"></a>(4) Time complexity</h3><p>Expected time complexity is $O(n \log n)$</p>
<h2 id="7-5-Extension-to-other-loss-functions"><a href="#7-5-Extension-to-other-loss-functions" class="headerlink" title="7.5 Extension to other loss functions"></a>7.5 Extension to other loss functions</h2><h3 id="1-Weighted-loss-functions"><a href="#1-Weighted-loss-functions" class="headerlink" title="(1) Weighted loss functions"></a>(1) Weighted loss functions</h3><p>The extension to $L_{\omega}$ allows for defining a family of loss functions that can emphasize different aspects of ranking, based on the weight function $\omega$:</p>
<p>$$<br>L_{\omega}(\sigma, \sigma^*) &#x3D; \frac{2}{n(n - 1)} \sum_{u \neq v} \omega(\sigma^*(v), \sigma^*(u)) \mathbf{1}<em>{\sigma(u) &lt; \sigma(v)} \mathbf{1}</em>{\sigma^*(v) &lt; \sigma^*(u)},<br>$$<br>where the sum runs over all pairs $(u, v)$ with distinct elements of $X$.</p>
<h3 id="2-Weight-function-omega"><a href="#2-Weight-function-omega" class="headerlink" title="(2) Weight function $\omega$"></a>(2) Weight function $\omega$</h3><p>It is a symmetric function, satisfying:</p>
<ul>
<li><p>Symmetry: $\omega(i, j) &#x3D; \omega(j, i)$ for all $i, j$.</p>
</li>
<li><p>Monotonicity: $\omega(i, j) \leq \omega(i, k)$ if either $i &lt; j &lt; k$ or $i &gt; j &gt; k$.</p>
</li>
<li><p>Triangle Inequality: $\omega(i, j) \leq \omega(i, k) + \omega(k, j)$.</p>
</li>
</ul>
<h3 id="3-Correct-order-importance"><a href="#3-Correct-order-importance" class="headerlink" title="(3) Correct order importance"></a>(3) Correct order importance</h3><p>The triangle inequality property stems from the idea that if correctly ordering elements in positions $(i,k)$ and $(k,j)$ is not of great importance, then correctly ordering $(i,j)$ should hold.</p>
<h1 id="8-Other-ranking-criteria"><a href="#8-Other-ranking-criteria" class="headerlink" title="8. Other ranking criteria"></a>8. Other ranking criteria</h1><h2 id="8-1-Precision-precision-n-average-precision-recall"><a href="#8-1-Precision-precision-n-average-precision-recall" class="headerlink" title="8.1 Precision, precision@n, average precision, recall"></a>8.1 Precision, precision@n, average precision, recall</h2><h3 id="1-Precision"><a href="#1-Precision" class="headerlink" title="(1) Precision"></a>(1) Precision</h3><p>Measures the accuracy of positive predictions</p>
<h3 id="2-Precision-n"><a href="#2-Precision-n" class="headerlink" title="(2) Precision @n"></a>(2) Precision @n</h3><p>Focuses on the top $n$ predictions</p>
<h3 id="3-Average-precision"><a href="#3-Average-precision" class="headerlink" title="(3) Average precision"></a>(3) Average precision</h3><p>Averages precision at various cutoff points</p>
<h3 id="4-Recall"><a href="#4-Recall" class="headerlink" title="(4) Recall"></a>(4) Recall</h3><p>Measures the completeness of positive predictions</p>
<h2 id="8-2-DCG-and-NDCG"><a href="#8-2-DCG-and-NDCG" class="headerlink" title="8.2 DCG and NDCG"></a>8.2 DCG and NDCG</h2><h3 id="1-DCG"><a href="#1-DCG" class="headerlink" title="(1) DCG"></a>(1) DCG</h3><p>Uses relevance scores and discount factors to measure the quality of ranking</p>
<h3 id="2-NDCG"><a href="#2-NDCG" class="headerlink" title="(2) NDCG"></a>(2) NDCG</h3><p>Normalizes DCG to allow comparison across different query sets</p>

    <div class="gallery">
        
    </div>
</main>

        

        <footer>
    <p>&copy; Brian Qian</p>
    <p>
        Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>,
        <a target="_blank" rel="noopener" href="https://github.com/sunnybyeon/hexo-theme-dashed">Theme</a> by
        <a target="_blank" rel="noopener" href="https://github.com/sunnybyeon">sunnybyeon</a>
    </p>
</footer>

    </body>
</html>
